# Overview
- thread, mutex, condition variable들의 사용법을 배웠다.
- 이러한 기본 요소들을 좀 더 세밀하게 컨트롤 할 수 있는 몇가지 요소에대해 살펴본다.

![image](https://user-images.githubusercontent.com/69780812/146664065-30504aa9-213a-459b-85b7-903f510ac77f.png)
- 기본적으로 CPU와 RAM(컴퓨터 메모리)는 물리적으로 떨어져있다.
  - 따라서 CPU가 메모리에서 데이터를 읽어오기 위해서는 꽤 많은 시간이 걸린다.
- 실제 intel의 i7-6700 CPU의 경우 최소 42 사이클 정도 걸린다고 한다. 덧셈 한 번을 1사이클에 끝낼 수 있는데, 메모리에서 데이터 불러오는 것을 기다리느라 42번 덧셈을 연산할 시간을 놓치게 된다.
  - 메모리에서 데이터 한번 읽을 때마다 42 사이클 동안 아무것도 못하는 것은 CPU 입장에서 굉장한 손해다.

# Cache
- 위와 같은 문제를 보완하기 위해 CPU 개발자들은 Cache라는 것을 도입했다.
- CPU 칩 안에 있는 조그마한 메모리라고 보면 된다.
  - RAM과는 다르게 CPU에서 연산을 수행하는 부분이랑 거의 붙어 있어 read/write 속도가 매우 빠르다.
- Cache의 크기는 그렇게 크지 않다.
  - intel i7-6700의 L1 cache : 32KB, L2 : 256KB, L3 : 8MB 정도
- 크기는 작지만 L1 읽기 쓰기 경우 단 4사이클, L2는 12사이클, L3는 36 사이클 정도로 메모리를 왔다 갔다 하는 것 보다 훨씬 빠른 속도로 접근할 수 있게된다.
- CPU에서 가장 많이 접근하는 메모리 영역은 L1 Cache에, 그 다음은 L2, L3 순으로 놓게 된다.
  - Cache가 특정 주소 데이터에 접근하려면 일단 캐시에 있는지 확인하고 있으면 해당 값을 읽고 없으면 메모리 까지 갔다오는 방식으로 진행된다.
  - 캐시에 있는 데이터를 요청해서 시간절약하는 것을 **Cache hit**, 데이터가 없어 메모리까지 갔다 오는 것을 **Cache miss**라고 부른다.
- Cache는 메모리를 읽으면 일단 저장하고 만일 캐시가 다 차면 특정한 방식에 따라 처리힌다.
  - CPU가 어느 영역의 메모리에 자주 접근하는지는 알 수 없다.
- 특정한 방식이라 함은 CPU마다 다르지만 예를들어 가장 이전에 쓴 cache를 날리고 그 자리에 새로운 Cache를 기록하는 방식이있다. (LRU-Least Recently Used)
  - LRU 방식은 최근 접근한 데이터를 자주 반복해서 접근하면 매우 유리하다는 점이 있다.

```cpp
for (int i = 0; i < 10000; i++)
{
    for (int j = 0; j < 10000; j++)
    {
        s += data[j];
    }
}
```

```cpp
for (int j = 0; i < 10000; i++)
{
    for (int i = 0; j < 10000; j++)
    {
        s += data[j];
    }
}
```
- Cache 크기가 1KB고, LRU 방식을 사용하는 CPU라고 가정해보자.
- 위 두 코드는 동일한 연산을 수행한다.
- 하지만 두 번째 방식이 더 빨리 동작한다.
  - 첫 번쨰 경우 data[0]을 접근하는 것을 생각해보면 data[0]은 첫 루프에서 cache에 들어가게 된다.
  - 하지만 크기가 매우 작아 j=256이 되었을 때, data[0]은 cache에서 사라지게 된다. (1KB = 1024 byte = int 256 개)
  - 따라서 i = 1인 루프에서 data[0]에 다시 접근 시 data[0]은 Cache에서 이미 사라진 이후여서 **Cache miss**가 발생하게 된다. 모든 원소 접근이 Cache miss로 느리게될 것이다.
  - 후자의 경우 data[0]을 10000 번 연속으로 접근해서 처음 접근 빼고 9999번 Cache hit 되어 빠르게 덧셈을 수행할 수 있게 된다.

# Computer는 사실 시키는 대로 하지 않는다.
![image](https://user-images.githubusercontent.com/69780812/146664323-6084eb4d-7f4d-4f55-ba6e-fd35de1c19d5.png)
- 코드를 짠대로 컴파일러가 그대로 기계어로 번역해 CPU가 해당 번역된 기계어를 그대로 실행한다면 오산이다.
- 위에서 foo() 입장에서는 큰 문제는 없을 것이다. 하지만 다른 thread에 있어서 a, b의 값을 확인하였을 때 코드가 순서대로 실행되었다면 b도 1, a도 1이어야하지만 a가 0인데 b가 1일 수 있다는 게 문제다.
  - 이는 현대 CPU가 한 번에 한 명령어씩 실행하는 것이 아니기 때문이다.

## CPU pipelining
![image](https://user-images.githubusercontent.com/69780812/146664358-c58f4ddd-7d5e-483b-a33a-9e56964e4b4e.png)
- 빨래하는 과정을 생각해보자.
- 여러 바구니의 빨래를 한다고 생각해보자. 위 처럼 한단계씩 차례대로 하는 방법도 있을 수 있다.
  - 한 바구니 빨래 세탁 - 건조 - 빨래개기 후 다른 바구니를 차례로 하면 될 것이다.
  - 하지만 위와 같은 방식을 효율적이지 않을 수 있다.

![image](https://user-images.githubusercontent.com/69780812/146664380-b403e523-f783-490f-ab1b-ae9c326562cc.png)
- 위 같이 모든 단계의 작업들을 쉬지 않고 계속 돌리는 방법이 있을 것이다.
- 이와 같이 **한 작업이 끝나기 전에 다음 작업을 시작하는 방식으로 동시에 여러개의 작업을 실행하는 것**을 **pipelining**이라고한다.

![image](https://user-images.githubusercontent.com/69780812/146664394-3c285064-0084-4a1a-bad5-2e36ea078524.png)
- CPU도 마찬가지로 실제 CPU 명령어를 실행할 때 여러 단계를 거치게 된다.
- 명렁어 읽기: fetch
- 읽은 명령어 해석: decode
- 해석된 명령어 실행: execute
- 결과 쓰기: write
- 위 사진에서는 각 단계의 실행 속도가 동일한 것 처럼 나타나지만 실제로는 실행 부분의 실행 속도는 명령어마다 천차 만별이다.
  - 오래걸리는 명령어가 있으면 해당 작업 때문에 다른 명령어들이 밀리게 될 것이다.
  - 예를들어 빨래개기는 30분만 걸리는데 건조기가 3시간 걸린다면 건조기 기다리느라 빨래를 할 수 없는 것과 마찬가지다. (세탁이 끝난 빨래를 쌓아놓을 수 없다는 전제하)
- 따라서 컴파일러는 어떠한 최대한 CPU의 파이프라인을 효율적으로 활용하도록 명령어를 재배치하게 된다.
  - 재배치 하더라도 최종 결과물은 달라지지 않도록 한다.
  - 문제는 컴파일러가 명령어 재배치 시 다른 thread들을 고려하지 않는다는 점이다. 따라서 멀티 스레드 환경에서는 예상치 못한 결과가 나올 수 있다.

```cpp
a = 1; // cache에 없음
b = 1; // cache에 있음
```
- 더 웃긴건 꼭 컴파일러만이 명령어를 재배치하는 것이아니다.
- a = 1의 경우 현재 a가 캐시에 없어 매우 오래걸린다.
- b = 1의 경우 캐시에 있어 빠르게 처리할 수 있다.
- 따라서 b = 1;이 a = 1; 보다 먼저 실행 될 수 잇다.
  - 그러므로 다른 thrad에서 a는 0인데 b가 1인 순간이 관찰될 수 있다는 것이다.
- 위 명령어처럼 read-read 순으로 나와 이를 RR 순서라고 한다. ARM의 CPU 경우 RR 명령어 재배치가 가능해서(intel은 금지하고 있다.) 위와 같은 상황이 발생할 수 있다.

# 그러면 우리보고 어쩌라고 ?
- C++의 모든 객체들은 수정 순서(modification order)라는 것을 정의할 수 있다.

![image](https://user-images.githubusercontent.com/69780812/146664726-8fd6a468-40f9-428d-b26a-20ade4135c0a.png)
- **modification order**라는 것은 만약 어떤 객체의 값을 실시간으로 확인할 수 있는 무언가가 있다고 하면 해당 객체의 값의 변화를 기록한 것이라 보면된다.
- 위 처럼 어떤 변수 a값이 위 형태로 변화해왔다고 해보자.
- C++에서 보장하는 사실은 원자적 연산을 할 경우에 **모든 thread에서 같은 객체에 대해 동일한 수정 순서를 관찰할 수 있다는 사실이**다.
  - 어떤 thread가 a 값을 읽었을 때 8로 읽었으면 그 다음에 읽어지는 a의 값은 반드시 8, 6, 3 중 하나여야할 것이다. 수정 순서를 거꾸로 거슬러서 5를 읽는 일은 없다.
- 모든 Thread에서 변수의 수정 순서에 동의하면 문제될 게 없다.
  - 같은 시간에 변수 a의 값을 관찰했다고 해서 굳이 **모든 스레드들이 동일한 값을 관찰할 필요는 없다**는 것이다.
  - thread 1과 thread 2에서 a의 값을 관찰했을 때 thread 1에서 5를 관찰하고 thread 2에서는 8을 관찰해도 문제될 것이 없다는 것이다.
  - 실행하는 순서가 달라도 결과만 같다면 문제가 안된다는 것이다.

![image](https://user-images.githubusercontent.com/69780812/146664829-b268592d-6f2a-487a-8e2d-96dcd3f9ddd4.png)
- thread 간 같은 시간에 변수의 값을 읽었을 때 다른 값을 리턴해도 된다는 것은 조금 충격적이다.. 이 조건을 강제할 수 없는 이유는 CPU 캐시가 각 코어별로 존재하기 때문이다.
  - 각 코어가 자신들의 L1, L2 캐시를 갖고있다는 것을 위 그림을 통해 알 수 있다.
  - thread1 에서 a=5를 하고 자신의 캐시에만 기록해 놓고 다른 코어들에 알리지 않으면 thread 3에서 a의 값을 확인할 때 5를 얻는 다는 보장이 없다는 뜻이다.
- 모든 캐시에 동기화를 시킬 수 있지만 이는 시간을 꽤나 잡아먹는 일일 것이다.
- C++은 로우레벨 언어 답게 이를 세밀하게 조정할 여러 도구를 제공하고 있다.

# 원자성 (atomicity)
- C++에서 모든 thread들이 수정 순서에 동의해야만 하는 경우는 모든 연산들이 **원자적일 때**라고 했다.
- 원자적 연산이 아닌 경우 모든 thread에서 같은 수정 순서를 관찰할 수 잇음이 보장되지 않아 직접 적절한 동기화 방법을 통해 처리해야만된다.
- 원자적 연산 : CPU가 명령어 1개로 처리하는 명령으로 중간에 다른 Thread가 끼어들 여지가 전혀없는 연산을 말한다.
  - 이 연산을 반 정도 했다는 있을 수 없고 이 연산을 했다 혹은 안했다만 존재할 수 있는 것이다.
  - 원자 처럼 쪼갤 수없다고 해서 원자적이라고 한다.
- 원자적 연산들은 올바른 연산을 위해 굳이 뮤텍스가 필요하지 않아 속도가 더 빠르다.

```cpp
#include <atomic>
#include <iostream>
#include <thread>
#include <vector>

void worker(std::atomic<int>& counter)
{
    for (int i = 0; i < 10000; i++)
    {
        counter++;
    }
}

int main()
{
    std::atomic<int> counter(0);

    std::vector<std::thread> workers;

    for (int i = 0; i < 4; i++)
    {
        workers.push_back(std::thread(worker, ref(counter)));
    }

    for (int i = 0; i < 4; i++)
        workers[i].join();
    
    std::cout << "Counter Result : " << counter << std::endl;
}
```

```
Counter Result : 40000
```
- atomic의 템플릿 인자로 원자적으로 만들고 싶은 Type을 전달하면된다.
  - 위 경우 0으로 초기화된 원자적인 변수를 정의한 것이다.
- 놀랍게도 아무런 mutex로 보호하지 않았음에도 제대로 출력했다.

![image](https://user-images.githubusercontent.com/69780812/146665012-7112e1fa-8c4d-412d-8c8e-b92ec942da4b.png)
- counter++ 하기 위해서는 CPU가 counter 값을 읽고 +1 하고, write하는 3단계를 거쳐야만 했다. 여기서는 lock 없이도 제대로 계산했다..
- 위를 보면 컴파일러가 원자적 연산으로 만들어주는 것을 확인할 수 있다.
- counter++ 부분이 실제로 어셈블리 명령 한 줄인 lock add DWORD PTR[ㄱ야], 1 로 나타난 것을 알 수 있다.
- 원래 CPU 는 한 명령어에서 메모리에 읽기 or 쓰기 둘 중하나 밖에 하지 못한다.
  - 하지만 lock add의 경우 rdi에 위치한 메모리를 읽고 1을 더하고 rdi에 위치한 메모리에 쓰기를 모두 해버린다.
  - 이러한 명령어를 컴파일러가 사용할 수 있었던 이유는 어느 CPU에서 실행할지 x86 컴파일러가 알고 있기 때문에 CPU 특이적인 명령어를 제공할 수 있던 것이다. (CPU에 따라 위 같은 명령이 없는 경우도 있긴하다.)

```cpp
std::atomic<int> x;
std::cout << "is lock free ? " << boolalpha << x.is_lock_free()
```

```
is lock free ? : true
```
- is_lock_free() 함수를 통해 atomic 객체의 연삳르이 정말로 원자적으로 구현될 수 있는지 확인할 수 있다.
- lock free의 lock과 실제 어셈블리 명렁의 lock과는 다른 lock을 의마한다.
  - 어셈블리 : 해당 명령을 원자적으로 수행하라는 의미
  - lock free : lock이 없다. 뮤텍스와 같은 객체들의 lock, unlock 없이도 해당 연산을 올바르게 수행할 수 있다는 뜻이다.
